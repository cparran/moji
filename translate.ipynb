{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Traductor de texto japonés a español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the transformers library from HuggingFace\n",
    "#! pip install transformers torch pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the sentencepiece and sacremoses libraries to tokenize the text\n",
    "#! pip install sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deep-translator\n",
      "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/carol/.pyenv/versions/3.10.6/envs/moji/lib/python3.10/site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/carol/.pyenv/versions/3.10.6/envs/moji/lib/python3.10/site-packages (from deep-translator) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/carol/.pyenv/versions/3.10.6/envs/moji/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/carol/.pyenv/versions/3.10.6/envs/moji/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/carol/.pyenv/versions/3.10.6/envs/moji/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/carol/.pyenv/versions/3.10.6/envs/moji/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/carol/.pyenv/versions/3.10.6/envs/moji/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.2.2)\n",
      "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m56.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: deep-translator\n",
      "Successfully installed deep-translator-1.11.4\n"
     ]
    }
   ],
   "source": [
    "# Install deep-translator to translate the text\n",
    "# ! pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree import ElementTree as ET\n",
    "from deep_translator import GoogleTranslator\n",
    "import os\n",
    "import html  # Importa la biblioteca html\n",
    "\n",
    "# Inicializa el traductor de Google del japonés al español\n",
    "traductor = GoogleTranslator(source='ja', target='es')\n",
    "\n",
    "# Cargar el archivo XML\n",
    "xml_path = 'data/Manga109s_released_2023_12_07/annotations/ARMS.xml'  # Asegúrate de especificar la ruta correcta al archivo XML\n",
    "tree = ET.parse(xml_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Obtener el nombre del archivo original sin la extensión\n",
    "file_name = os.path.splitext(os.path.basename(xml_path))[0]\n",
    "\n",
    "# Iterar sobre cada elemento 'text'\n",
    "for text_element in root.findall('.//text'):\n",
    "    # Extraer el texto japonés\n",
    "    japanese_text = text_element.text.strip()\n",
    "    \n",
    "    # Verificar que el texto no esté vacío antes de traducir\n",
    "    if japanese_text:\n",
    "        # Traduce el texto extraído al español\n",
    "        translated_text = traductor.translate(japanese_text)\n",
    "        \n",
    "        # Verifica que translated_text no sea None antes de decodificar las entidades HTML\n",
    "        if translated_text:\n",
    "            # Decodificar las entidades HTML a caracteres normales\n",
    "            translated_text = html.unescape(translated_text)\n",
    "        else:\n",
    "            # Manejar el caso en que translated_text es None\n",
    "            # Por ejemplo, puedes optar por dejar el texto original o aplicar una etiqueta predeterminada\n",
    "            translated_text = \"Texto no disponible\"\n",
    "        \n",
    "        # Opción 1: Agregar el texto traducido como un nuevo atributo\n",
    "        text_element.set('translated_text', translated_text)\n",
    "        \n",
    "        # Opción 2 (Alternativa): Crear y agregar un nuevo elemento hijo con el texto traducido\n",
    "        # Si prefieres esta opción, descomenta las siguientes dos líneas:\n",
    "        # new_element = ET.SubElement(text_element, \"translatedText\")\n",
    "        # new_element.text = translated_text\n",
    "\n",
    "# Generar el nombre del archivo de salida con el sufijo \"-es\"\n",
    "output_file_name = f\"{file_name}-es.xml\"\n",
    "\n",
    "# Guardar el archivo XML modificado, asegurándose de usar utf-8 como la codificación\n",
    "tree.write(output_file_name, encoding=\"utf-8\", xml_declaration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo traducido guardado como: ARMS-es.xml\n"
     ]
    }
   ],
   "source": [
    "# LLama a la función traducir_archivo_xml\n",
    "\n",
    "from traductor_xml import traducir_archivo_xml\n",
    "\n",
    "xml_input_path = 'data/Manga109s_released_2023_12_07/annotations/ARMS.xml'\n",
    "traducir_archivo_xml(xml_input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /home/carol/.pyenv/versions/3.10.6/envs/moji/lib/python3.10/site-packages (10.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones =[\n",
    "    {\n",
    "      \"x\": 38,\n",
    "      \"y\": 186,\n",
    "      \"width\": 76,\n",
    "      \"height\": 104,\n",
    "      \"confidence\": 0.968,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"17569616-e20a-4d55-9c40-cced0b155947\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 192.5,\n",
    "      \"y\": 139,\n",
    "      \"width\": 63,\n",
    "      \"height\": 126,\n",
    "      \"confidence\": 0.966,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"07b4c1d3-e5ef-4f21-8e97-437ce2760b6e\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 215,\n",
    "      \"y\": 407,\n",
    "      \"width\": 52,\n",
    "      \"height\": 128,\n",
    "      \"confidence\": 0.964,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"707a7810-1e27-403d-9dd2-bef84d857580\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 320,\n",
    "      \"y\": 372,\n",
    "      \"width\": 30,\n",
    "      \"height\": 56,\n",
    "      \"confidence\": 0.958,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"03aad0a9-d5b4-481f-8f72-ffc9a74a0a53\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 140,\n",
    "      \"y\": 293,\n",
    "      \"width\": 44,\n",
    "      \"height\": 68,\n",
    "      \"confidence\": 0.954,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"6eb54e33-3eff-4496-9b73-2522e4fe5885\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 304,\n",
    "      \"y\": 95.5,\n",
    "      \"width\": 42,\n",
    "      \"height\": 67,\n",
    "      \"confidence\": 0.953,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"7929a6c2-e7cc-43c9-857d-31c9983031f5\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 35,\n",
    "      \"y\": 79.5,\n",
    "      \"width\": 58,\n",
    "      \"height\": 61,\n",
    "      \"confidence\": 0.948,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"3317f256-efca-4c17-9cba-23cf612f8c32\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 266,\n",
    "      \"y\": 216.5,\n",
    "      \"width\": 144,\n",
    "      \"height\": 61,\n",
    "      \"confidence\": 0.931,\n",
    "      \"class\": \"text_free\",\n",
    "      \"class_id\": 1,\n",
    "      \"detection_id\": \"ffd4e0a2-b673-40a8-aa82-3b7670508fc0\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 137,\n",
    "      \"y\": 77,\n",
    "      \"width\": 32,\n",
    "      \"height\": 56,\n",
    "      \"confidence\": 0.927,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"17883f57-c1c3-4ebb-b25d-9034c175205d\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 139.5,\n",
    "      \"y\": 158.5,\n",
    "      \"width\": 23,\n",
    "      \"height\": 49,\n",
    "      \"confidence\": 0.863,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"9eac7df8-a22a-4946-8e7e-013ae09c9ddf\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 209,\n",
    "      \"y\": 279,\n",
    "      \"width\": 30,\n",
    "      \"height\": 38,\n",
    "      \"confidence\": 0.862,\n",
    "      \"class\": \"text_bubble\",\n",
    "      \"class_id\": 0,\n",
    "      \"detection_id\": \"36dec3cc-455e-43ee-a1de-6cf2f8d57067\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 261,\n",
    "      \"y\": 282.5,\n",
    "      \"width\": 12,\n",
    "      \"height\": 41,\n",
    "      \"confidence\": 0.854,\n",
    "      \"class\": \"text_free\",\n",
    "      \"class_id\": 1,\n",
    "      \"detection_id\": \"4cda5390-644e-4f45-be59-8ac8637e27c2\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 315.5,\n",
    "      \"y\": 281.5,\n",
    "      \"width\": 11,\n",
    "      \"height\": 31,\n",
    "      \"confidence\": 0.851,\n",
    "      \"class\": \"text_free\",\n",
    "      \"class_id\": 1,\n",
    "      \"detection_id\": \"f73983f9-803b-463b-9a48-a77609f6d25a\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 80.5,\n",
    "      \"y\": 23.5,\n",
    "      \"width\": 157,\n",
    "      \"height\": 47,\n",
    "      \"confidence\": 0.752,\n",
    "      \"class\": \"text_free\",\n",
    "      \"class_id\": 1,\n",
    "      \"detection_id\": \"b5066525-60d9-43dc-aa9c-a6418e9cb6ed\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 288.5,\n",
    "      \"y\": 274.5,\n",
    "      \"width\": 17,\n",
    "      \"height\": 49,\n",
    "      \"confidence\": 0.713,\n",
    "      \"class\": \"text_free\",\n",
    "      \"class_id\": 1,\n",
    "      \"detection_id\": \"71a4adeb-362e-4b6c-8aa2-9d053dd07e07\"\n",
    "    },\n",
    "    {\n",
    "      \"x\": 252.5,\n",
    "      \"y\": 492,\n",
    "      \"width\": 129,\n",
    "      \"height\": 40,\n",
    "      \"confidence\": 0.694,\n",
    "      \"class\": \"text_free\",\n",
    "      \"class_id\": 1,\n",
    "      \"detection_id\": \"0d224f1c-048f-4906-9eae-876feba9017c\"\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 38,\n",
       "  'y': 186,\n",
       "  'width': 76,\n",
       "  'height': 104,\n",
       "  'confidence': 0.968,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '17569616-e20a-4d55-9c40-cced0b155947'},\n",
       " {'x': 192.5,\n",
       "  'y': 139,\n",
       "  'width': 63,\n",
       "  'height': 126,\n",
       "  'confidence': 0.966,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '07b4c1d3-e5ef-4f21-8e97-437ce2760b6e'},\n",
       " {'x': 215,\n",
       "  'y': 407,\n",
       "  'width': 52,\n",
       "  'height': 128,\n",
       "  'confidence': 0.964,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '707a7810-1e27-403d-9dd2-bef84d857580'},\n",
       " {'x': 320,\n",
       "  'y': 372,\n",
       "  'width': 30,\n",
       "  'height': 56,\n",
       "  'confidence': 0.958,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '03aad0a9-d5b4-481f-8f72-ffc9a74a0a53'},\n",
       " {'x': 140,\n",
       "  'y': 293,\n",
       "  'width': 44,\n",
       "  'height': 68,\n",
       "  'confidence': 0.954,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '6eb54e33-3eff-4496-9b73-2522e4fe5885'},\n",
       " {'x': 304,\n",
       "  'y': 95.5,\n",
       "  'width': 42,\n",
       "  'height': 67,\n",
       "  'confidence': 0.953,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '7929a6c2-e7cc-43c9-857d-31c9983031f5'},\n",
       " {'x': 35,\n",
       "  'y': 79.5,\n",
       "  'width': 58,\n",
       "  'height': 61,\n",
       "  'confidence': 0.948,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '3317f256-efca-4c17-9cba-23cf612f8c32'},\n",
       " {'x': 266,\n",
       "  'y': 216.5,\n",
       "  'width': 144,\n",
       "  'height': 61,\n",
       "  'confidence': 0.931,\n",
       "  'class': 'text_free',\n",
       "  'class_id': 1,\n",
       "  'detection_id': 'ffd4e0a2-b673-40a8-aa82-3b7670508fc0'},\n",
       " {'x': 137,\n",
       "  'y': 77,\n",
       "  'width': 32,\n",
       "  'height': 56,\n",
       "  'confidence': 0.927,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '17883f57-c1c3-4ebb-b25d-9034c175205d'},\n",
       " {'x': 139.5,\n",
       "  'y': 158.5,\n",
       "  'width': 23,\n",
       "  'height': 49,\n",
       "  'confidence': 0.863,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '9eac7df8-a22a-4946-8e7e-013ae09c9ddf'},\n",
       " {'x': 209,\n",
       "  'y': 279,\n",
       "  'width': 30,\n",
       "  'height': 38,\n",
       "  'confidence': 0.862,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '36dec3cc-455e-43ee-a1de-6cf2f8d57067'},\n",
       " {'x': 261,\n",
       "  'y': 282.5,\n",
       "  'width': 12,\n",
       "  'height': 41,\n",
       "  'confidence': 0.854,\n",
       "  'class': 'text_free',\n",
       "  'class_id': 1,\n",
       "  'detection_id': '4cda5390-644e-4f45-be59-8ac8637e27c2'},\n",
       " {'x': 315.5,\n",
       "  'y': 281.5,\n",
       "  'width': 11,\n",
       "  'height': 31,\n",
       "  'confidence': 0.851,\n",
       "  'class': 'text_free',\n",
       "  'class_id': 1,\n",
       "  'detection_id': 'f73983f9-803b-463b-9a48-a77609f6d25a'},\n",
       " {'x': 80.5,\n",
       "  'y': 23.5,\n",
       "  'width': 157,\n",
       "  'height': 47,\n",
       "  'confidence': 0.752,\n",
       "  'class': 'text_free',\n",
       "  'class_id': 1,\n",
       "  'detection_id': 'b5066525-60d9-43dc-aa9c-a6418e9cb6ed'},\n",
       " {'x': 288.5,\n",
       "  'y': 274.5,\n",
       "  'width': 17,\n",
       "  'height': 49,\n",
       "  'confidence': 0.713,\n",
       "  'class': 'text_free',\n",
       "  'class_id': 1,\n",
       "  'detection_id': '71a4adeb-362e-4b6c-8aa2-9d053dd07e07'},\n",
       " {'x': 252.5,\n",
       "  'y': 492,\n",
       "  'width': 129,\n",
       "  'height': 40,\n",
       "  'confidence': 0.694,\n",
       "  'class': 'text_free',\n",
       "  'class_id': 1,\n",
       "  'detection_id': '0d224f1c-048f-4906-9eae-876feba9017c'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Función para obtener el texto de una región en la imagen\n",
    "def obtener_texto(imagen, region):\n",
    "    region_imagen = imagen.crop((region['x'], region['y'], region['x'] + region['width'], region['y'] + region['height']))\n",
    "    texto = pytesseract.image_to_string(region_imagen)\n",
    "    return texto\n",
    "\n",
    "# Tu lista de predicciones\n",
    "predicciones = predicciones\n",
    "\n",
    "# Cargar la imagen\n",
    "imagen_path = \"/home/carol/code/cparran/MOJI/data/_05.jpg\"\n",
    "imagen = Image.open(imagen_path)\n",
    "\n",
    "# Iterar sobre las predicciones y agregar la nueva clase\n",
    "for prediccion in predicciones:\n",
    "    texto = obtener_texto(imagen, prediccion)\n",
    "    prediccion['texto'] = texto\n",
    "    prediccion['clase'] = \"texto\"\n",
    "\n",
    "# Ahora, tus predicciones tendrán un campo 'texto' y 'clase' con información sobre el texto detectado y la clase asignada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Función para obtener el texto de una región en la imagen\n",
    "def obtener_texto(imagen, region):\n",
    "    region_imagen = imagen.crop((region['x'], region['y'], region['x'] + region['width'], region['y'] + region['height']))\n",
    "    texto = pytesseract.image_to_string(region_imagen, lang='jpn', config='--psm 6 --oem 3')\n",
    "    return texto\n",
    "\n",
    "# Tus predicciones\n",
    "predicciones = [\n",
    "    {\n",
    "        \"x\": 184.5,\n",
    "        \"y\": 140,\n",
    "        \"width\": 63,\n",
    "        \"height\": 126,\n",
    "        \"confidence\": 0.964,\n",
    "        \"class\": \"text_bubble\",\n",
    "        \"class_id\": 0,\n",
    "        \"detection_id\": \"5e8364f3-0623-4b09-aa01-2bfd9075d912\"\n",
    "    },\n",
    "    {\n",
    "        \"x\": 132,\n",
    "        \"y\": 294,\n",
    "        \"width\": 44,\n",
    "        \"height\": 68,\n",
    "        \"confidence\": 0.959,\n",
    "        \"class\": \"text_bubble\",\n",
    "        \"class_id\": 0,\n",
    "        \"detection_id\": \"eb3a0a1e-3e8f-4fbe-b6a4-7d8c0e5b81d0\"\n",
    "    },\n",
    "    # ... (resto de tus predicciones)\n",
    "]\n",
    "\n",
    "# Ruta de la imagen\n",
    "imagen_path = \"/home/carol/code/cparran/MOJI/data/_05.jpg\"\n",
    "imagen = Image.open(imagen_path)\n",
    "\n",
    "# Iterar sobre las predicciones y agregar la nueva clase\n",
    "for prediccion in predicciones:\n",
    "    texto = obtener_texto(imagen, prediccion)\n",
    "    prediccion['texto'] = texto\n",
    "    prediccion['clase'] = \"texto\"\n",
    "\n",
    "# Ahora, tus predicciones tendrán un campo 'texto' y 'clase' con información sobre el texto detectado y la clase asignada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 184.5,\n",
       "  'y': 140,\n",
       "  'width': 63,\n",
       "  'height': 126,\n",
       "  'confidence': 0.964,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '5e8364f3-0623-4b09-aa01-2bfd9075d912',\n",
       "  'texto': ' \\n\\x0c',\n",
       "  'clase': 'texto'},\n",
       " {'x': 132,\n",
       "  'y': 294,\n",
       "  'width': 44,\n",
       "  'height': 68,\n",
       "  'confidence': 0.959,\n",
       "  'class': 'text_bubble',\n",
       "  'class_id': 0,\n",
       "  'detection_id': 'eb3a0a1e-3e8f-4fbe-b6a4-7d8c0e5b81d0',\n",
       "  'texto': '\\x0c',\n",
       "  'clase': 'texto'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicciones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
